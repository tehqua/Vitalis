{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0191d968",
   "metadata": {},
   "source": [
    "# 1. Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "857f091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lammi\\Downloads\\medscreening\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from io import BytesIO\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import snapshot_download\n",
    "import keras\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f776e",
   "metadata": {},
   "source": [
    "# 2. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ca7429",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().parents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d5e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = (\n",
    "    PROJECT_ROOT\n",
    "    / \"agents\"\n",
    "    / \"image_process\"\n",
    "    / \"data\"\n",
    "    / \"pediatric_skin_data\"\n",
    ")\n",
    "\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"data\" / \"outputs\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e620aa",
   "metadata": {},
   "source": [
    "# 3. Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f178e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_samples(\n",
    "    data_dir: Path,\n",
    "    max_per_label: int = 1000,\n",
    "    seed: int = 42,\n",
    ") -> List[Tuple[str, int, str]]:\n",
    "    rng = random.Random(seed)\n",
    "    samples: List[Tuple[str, int, str]] = []\n",
    "\n",
    "    for class_dir in sorted(data_dir.iterdir()):\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        label_id, class_name = class_dir.name.split(\"_\", 1)\n",
    "\n",
    "        image_paths = [\n",
    "            p\n",
    "            for p in class_dir.iterdir()\n",
    "            if p.suffix.lower() in {\".jpg\", \".jpeg\", \".png\"}\n",
    "        ]\n",
    "\n",
    "        rng.shuffle(image_paths)\n",
    "\n",
    "        for img_path in image_paths[:max_per_label]:\n",
    "            samples.append(\n",
    "                (\n",
    "                    str(img_path),\n",
    "                    int(label_id),\n",
    "                    class_name,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d594855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 8000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Users\\lammi\\Downloads\\medscreening\\agents\\i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Eczema_Dermatitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:\\Users\\lammi\\Downloads\\medscreening\\agents\\i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Eczema_Dermatitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:\\Users\\lammi\\Downloads\\medscreening\\agents\\i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Eczema_Dermatitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:\\Users\\lammi\\Downloads\\medscreening\\agents\\i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Eczema_Dermatitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:\\Users\\lammi\\Downloads\\medscreening\\agents\\i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Eczema_Dermatitis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  label         class_name\n",
       "0  c:\\Users\\lammi\\Downloads\\medscreening\\agents\\i...      0  Eczema_Dermatitis\n",
       "1  c:\\Users\\lammi\\Downloads\\medscreening\\agents\\i...      0  Eczema_Dermatitis\n",
       "2  c:\\Users\\lammi\\Downloads\\medscreening\\agents\\i...      0  Eczema_Dermatitis\n",
       "3  c:\\Users\\lammi\\Downloads\\medscreening\\agents\\i...      0  Eczema_Dermatitis\n",
       "4  c:\\Users\\lammi\\Downloads\\medscreening\\agents\\i...      0  Eczema_Dermatitis"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = collect_samples(\n",
    "    DATA_DIR,\n",
    "    max_per_label=1000,\n",
    ")\n",
    "\n",
    "metadata = pd.DataFrame(\n",
    "    samples,\n",
    "    columns=[\"path\", \"label\", \"class_name\"],\n",
    ")\n",
    "\n",
    "metadata.to_csv(\n",
    "    OUTPUT_DIR / \"metadata.csv\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "print(\"Total images:\", len(metadata))\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e152467e",
   "metadata": {},
   "source": [
    "# 4. Embeddings Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "872e3d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid.\n",
      "Your token has been saved to C:\\Users\\lammi\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "if not hf_token:\n",
    "    raise RuntimeError(\"not found HF_TOKEN in environment variables\")\n",
    "\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ada8e550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dir = snapshot_download(\"google/derm-foundation\")\n",
    "\n",
    "layer = keras.layers.TFSMLayer(\n",
    "    model_dir,\n",
    "    call_endpoint=\"serving_default\"\n",
    ")\n",
    "\n",
    "model = keras.Sequential([layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e4d759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_tf(path: str):\n",
    "    image_bytes = tf.io.read_file(path)\n",
    "\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                \"image/encoded\": tf.train.Feature(\n",
    "                    bytes_list=tf.train.BytesList(\n",
    "                        value=[image_bytes.numpy()])\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    serialized = example.SerializeToString()\n",
    "\n",
    "    output = layer(inputs=tf.constant([serialized]))\n",
    "\n",
    "    emb = output[\"embedding\"].numpy().squeeze()\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f2ed31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c3524da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [7:32:57<00:00,  3.40s/it]  \n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "for _, row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
    "    try:\n",
    "        emb = encode_image_tf(row[\"path\"])\n",
    "        embeddings.append(emb)\n",
    "        labels.append(row[\"label\"])\n",
    "    except Exception as exc:\n",
    "        print(f\"Skip {row['path']}: {exc}\")\n",
    "\n",
    "X = np.stack(embeddings)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86906af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding DataFrame shape: (8000, 6145)\n",
      "label\n",
      "0    1000\n",
      "1    1000\n",
      "2    1000\n",
      "3    1000\n",
      "4    1000\n",
      "5    1000\n",
      "6    1000\n",
      "7    1000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "embedding_df = pd.DataFrame(X)\n",
    "embedding_df[\"label\"] = y\n",
    "\n",
    "print(\"Embedding DataFrame shape:\", embedding_df.shape)\n",
    "print(embedding_df[\"label\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f507a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split sizes:\n",
      "Train: 5600\n",
      "Val:   1200\n",
      "Test:  1200\n",
      "\n",
      "Train label distribution:\n",
      "label\n",
      "0    0.125\n",
      "1    0.125\n",
      "2    0.125\n",
      "3    0.125\n",
      "4    0.125\n",
      "5    0.125\n",
      "6    0.125\n",
      "7    0.125\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Val label distribution:\n",
      "label\n",
      "0    0.125\n",
      "1    0.125\n",
      "2    0.125\n",
      "3    0.125\n",
      "4    0.125\n",
      "5    0.125\n",
      "6    0.125\n",
      "7    0.125\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test label distribution:\n",
      "label\n",
      "0    0.125\n",
      "1    0.125\n",
      "2    0.125\n",
      "3    0.125\n",
      "4    0.125\n",
      "5    0.125\n",
      "6    0.125\n",
      "7    0.125\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "train_df, temp_df = train_test_split(\n",
    "    embedding_df,\n",
    "    test_size=0.30,\n",
    "    stratify=embedding_df[\"label\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.50,\n",
    "    stratify=temp_df[\"label\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"\\nSplit sizes:\")\n",
    "print(\"Train:\", len(train_df))\n",
    "print(\"Val:  \", len(val_df))\n",
    "print(\"Test: \", len(test_df))\n",
    "\n",
    "print(\"\\nTrain label distribution:\")\n",
    "print(train_df[\"label\"].value_counts(normalize=True).sort_index())\n",
    "\n",
    "print(\"\\nVal label distribution:\")\n",
    "print(val_df[\"label\"].value_counts(normalize=True).sort_index())\n",
    "\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(test_df[\"label\"].value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b002e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved files:\n",
      "c:\\Users\\lammi\\Downloads\\medscreening\\data\\outputs\\train_embeddings.csv\n",
      "c:\\Users\\lammi\\Downloads\\medscreening\\data\\outputs\\val_embeddings.csv\n",
      "c:\\Users\\lammi\\Downloads\\medscreening\\data\\outputs\\test_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = Path(OUTPUT_DIR)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_df.to_csv(OUTPUT_DIR / \"train_embeddings.csv\", index=False)\n",
    "val_df.to_csv(OUTPUT_DIR / \"val_embeddings.csv\", index=False)\n",
    "test_df.to_csv(OUTPUT_DIR / \"test_embeddings.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved files:\")\n",
    "print(OUTPUT_DIR / \"train_embeddings.csv\")\n",
    "print(OUTPUT_DIR / \"val_embeddings.csv\")\n",
    "print(OUTPUT_DIR / \"test_embeddings.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
